{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Training and testing data\n",
        "correct_sentences = [\n",
        "    \"There they saw something extraordinary, far exceeding what they knew.\",\n",
        "    \"Their knowledge of those facts was incomplete.\",\n",
        "    \"Their knowledge of those data was incomplete.\",\n",
        "    \"They’re going to learn something new from the ML course.\",\n",
        "    \"He is driving the car to the store.\",\n",
        "    \"He is driving the car to the picnic.\",\n",
        "    \"She walked to the park with her friends.\",\n",
        "    \"She walked to the park with her parents.\",\n",
        "    \"The cat chased the mouse around the house.\",\n",
        "    \"The cat chased the mouse around the car.\",\n",
        "    \"He walked to the mountain.\",\n",
        "    \"He walked to the park.\",\n",
        "]\n",
        "\n",
        "incorrect_sentences = [\n",
        "    \"They’re they saw something extraordinary, far exceeding what they knew.\",\n",
        "    \"There knowledge of those facts was incomplete.\",\n",
        "    \"There knowledge of those data was incomplete.\",\n",
        "    \"Their going to learn something new from the ML course.\",\n",
        "    \"He are driving the car to the store.\",\n",
        "    \"He are driving the car to the picnic.\",\n",
        "    \"She walk to the park with her friends.\",\n",
        "    \"She walk to the park with her parents.\",\n",
        "    \"The cat chase the mouse around the house.\",\n",
        "    \"The cat chase the mouse around the car.\",\n",
        "    \"He walk to the mountain.\",\n",
        "    \"He walk to the park.\",\n",
        "]\n",
        "\n",
        "# Mapping of misused words to correct alternatives\n",
        "word_corrections = {\n",
        "    'They’re': 'There',\n",
        "    'There': 'Their',\n",
        "    'Their': 'They’re',\n",
        "    'walk': 'walked',\n",
        "    'are': 'is',\n",
        "    'chase': 'chased'\n",
        "}"
      ],
      "metadata": {
        "id": "uvkJBcJ9YhiJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine correct and incorrect sentences into one dataset\n",
        "all_sentences = correct_sentences + incorrect_sentences\n",
        "all_labels = [0] * len(correct_sentences) + [1] * len(incorrect_sentences)\n",
        "\n",
        "# Splitting into train and test sets\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(all_sentences, all_labels, test_size=0.2, random_state=100)"
      ],
      "metadata": {
        "id": "6N_SWFeTati3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "word_to_ix = {}\n",
        "for sentence in all_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "# Tokenize sentences with handling OOV words\n",
        "def convert_to_sequences(sentences, word_to_ix):\n",
        "    unk_token = len(word_to_ix)  # Assign a unique index for the <unk> token\n",
        "    sentence_sequences = []\n",
        "    for sentence in sentences:\n",
        "        sequence = [word_to_ix[word] if word in word_to_ix else unk_token for word in sentence.split()]\n",
        "        sentence_sequences.append(sequence)\n",
        "    # Padding sequences\n",
        "    max_len = max(len(seq) for seq in sentence_sequences)\n",
        "    padded_sequences = [seq + [0] * (max_len - len(seq)) for seq in sentence_sequences]\n",
        "    return torch.tensor(padded_sequences, dtype=torch.long)\n",
        "\n",
        "train_inputs = convert_to_sequences(train_sentences, word_to_ix)\n",
        "test_inputs = convert_to_sequences(test_sentences, word_to_ix)\n",
        "\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long)"
      ],
      "metadata": {
        "id": "otpIjY6Fcimg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])  # Get the last output from the sequence\n",
        "        return output\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "vocab_size = len(word_to_ix)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 64\n",
        "output_size = 2  # Binary classification: 0 for correct, 1 for incorrect\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "v1m_SPpweiEN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_inputs)\n",
        "    loss = criterion(output, train_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76LIqDKGgqHN",
        "outputId": "ebd5faf5-071c-4333-ea02-b163296db346"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.6832\n",
            "Epoch [20/100], Loss: 0.6046\n",
            "Epoch [30/100], Loss: 0.2425\n",
            "Epoch [40/100], Loss: 0.0581\n",
            "Epoch [50/100], Loss: 0.0045\n",
            "Epoch [60/100], Loss: 0.0027\n",
            "Epoch [70/100], Loss: 0.0039\n",
            "Epoch [80/100], Loss: 0.0032\n",
            "Epoch [90/100], Loss: 0.0028\n",
            "Epoch [100/100], Loss: 0.0024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to detect misused words and propose corrections\n",
        "def detect_misused_words(sentence, word_corrections):\n",
        "    misused_words = []\n",
        "    for word in sentence.split():\n",
        "        if word in word_corrections:\n",
        "            misused_words.append((word, word_corrections[word]))\n",
        "    return misused_words"
      ],
      "metadata": {
        "id": "We7-6dXKgro3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set and detect misused words\n",
        "with torch.no_grad():\n",
        "    output = model(test_inputs)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct = (predicted == test_labels).sum().item()\n",
        "    total = test_labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    print(f'Accuracy on Test Set: {accuracy:.2f}% \\n')\n",
        "\n",
        "    print('****Incorrect Sentences**** \\n')\n",
        "\n",
        "    # Detect misused words in test sentences\n",
        "    for i, sentence in enumerate(test_sentences):\n",
        "        if predicted[i] == 1:  # If the sentence is predicted as incorrect\n",
        "            print(f'Sentence: {sentence}')\n",
        "            misused_words = detect_misused_words(sentence, word_corrections)\n",
        "            if misused_words:\n",
        "                for word, correction in misused_words:\n",
        "                    print(f'Misused words detected: {word}')\n",
        "                    print(f'Correct alternative word: {correction} \\n')\n",
        "            else:\n",
        "                print('No misused words detected. \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu_INvGahv0t",
        "outputId": "8995ffce-3570-4630-c112-6f267cf11266"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 100.00% \n",
            "\n",
            "****Incorrect Sentences**** \n",
            "\n",
            "Sentence: She walk to the park with her friends.\n",
            "Misused words detected: walk\n",
            "Correct alternative word: walked \n",
            "\n",
            "Sentence: The cat chase the mouse around the car.\n",
            "Misused words detected: chase\n",
            "Correct alternative word: chased \n",
            "\n",
            "Sentence: There knowledge of those facts was incomplete.\n",
            "Misused words detected: There\n",
            "Correct alternative word: Their \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0o9G9ghjdBu"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}